{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFT6201 Big Data \n",
    "# Trimester 3 2022\n",
    "# Assignment 3\n",
    "    \n",
    "# Contributors:     Suyog Belbase c3341354,\n",
    "#                   Deepa Bhattarai c3417299,\n",
    "#                   Julia-Rose Brown c3194432, \n",
    "#                   Matthew Griffiths c3365589,\n",
    "#                   Anton Komala c3384823 \n",
    "# Date:             12-11-2022\n",
    "# Description:      Perform analysis on the US Traffic Dataset including exploration of the dataset, statistical analysis\n",
    "#                   predictive modelling of the Severity variable\n",
    "# Package Versions: Python v3.9.13, Jupyter Notebooks v6.4.12, Scipy v1.9.3, Matplotlib v3.5.3, Imblearn v0.9.1,\n",
    "#                   Seaborn v0.12.0, Sci-kit learn v1.1.3, Wordcloud v1.8.2.2, Pingouin v0.5.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QAxc7ec8VD6v"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# Basic libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from scipy import stats\n",
    "from pingouin import welch_anova\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "\n",
    "# Visualisation libraries\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.colors import ListedColormap \n",
    "import seaborn as sns\n",
    "\n",
    "# Modelling libraries\n",
    "\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Set styles and display options\n",
    "pd.options.display.precision = 2 # display dataframes to 2 decimal points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pTL8RjciSDFD"
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "def farenheit_to_celsius(farenheit):\n",
    "  return ((farenheit - 32) * (5/9))\n",
    "\n",
    "def m_to_km(m):\n",
    "  return (m*1.609344)\n",
    "\n",
    "def in_to_mm(i):\n",
    "  return (i*25.4)\n",
    "\n",
    "# Function to retrieve performance metrics\n",
    "def scores(name, y_test, y_pred):\n",
    "        list = [name,\n",
    "                precision_score(y_test, y_pred, average='weighted'),\n",
    "                recall_score(y_test, y_pred, average='weighted'),\n",
    "                f1_score(y_test, y_pred, average='weighted'),\n",
    "                accuracy_score(y_test, y_pred)]\n",
    "        return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('ny_accidents.csv')\n",
    "\n",
    "# Drop columns that won't be used\n",
    "cols = ['Unnamed: 0','Number', 'Airport_Code', 'Timezone', 'Country', 'State', 'Civil_Twilight','Nautical_Twilight','Astronomical_Twilight','Turning_Loop']\n",
    "df.drop(cols, axis=1, inplace=True)\n",
    "\n",
    "df.drop_duplicates() # Drop duplicates\n",
    "df.dropna(inplace = True) # Drop rows with na values\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xri4BIiYTHzR"
   },
   "outputs": [],
   "source": [
    "# Pre-process of data\n",
    "# Rename columns \n",
    "df.rename(columns = {'Distance.mi.':'Distance',\n",
    "                     'Wind_Speed.mph.':'Wind_Speed',\n",
    "                     'Temperature.F.':'Temperature',\n",
    "                     'Wind_Chill.F.':'Wind_Chill',\n",
    "                     'Humidity...':'Humidity',\n",
    "                     'Pressure.in.':'Pressure',\n",
    "                     'Visibility.mi.':'Visibility',\n",
    "                     'Precipitation.in.':'Precipitation'}, inplace=True)\n",
    "\n",
    "## Variable groups as lists\n",
    "weather = ['Temperature', 'Humidity', 'Pressure','Visibility','Wind_Direction','Wind_Speed','Precipitation','Weather_Condition']\n",
    "poi = ['Amenity','Bump','Crossing','Give_Way','Junction','No_Exit','Railway','Roundabout','Station','Stop','Traffic_Calming','Traffic_Signal']\n",
    "\n",
    "# Convert dates & times to datetime type\n",
    "cols = ['Start_Time','End_Time','Weather_Timestamp']\n",
    "df[cols] = df[cols].apply(pd.to_datetime, errors='coerce')\n",
    "\n",
    "# Convert imperial units to metric\n",
    "df[['Temperature', 'Wind_Chill']] = df[['Temperature', 'Wind_Chill']].apply(farenheit_to_celsius) # farenheit to celsius\n",
    "df[['Visibility', 'Wind_Speed']] = df[['Visibility', 'Wind_Speed']].apply(m_to_km) # miles to kilometres\n",
    "df['Precipitation'] = df['Precipitation'].apply(in_to_mm) # inches to mm\n",
    "\n",
    "# Add severity_cat column\n",
    "conditions  = [ df['Severity'] == 1, df['Severity'] == 2, df['Severity'] == 3, df['Severity'] == 4 ]\n",
    "choices     = [ 'Low','Medium','High','Very High']\n",
    "df['severitycat'] = np.select(conditions, choices, default=np.nan)\n",
    "\n",
    "# Add highway column\n",
    "keywords = ['Pkwy', 'Parkway', 'I-', 'Interstate', 'Expy', 'Exp', 'Expressway', 'Route', 'State', 'NY', 'Trwy', 'Throughway', 'US', 'Hwy', 'Highway', 'Wyck', '9n']\n",
    "df['Highway'] = False #where False = other\n",
    "df.loc[df['Street'].str.contains('|'.join(keywords), case = False) == True, 'Highway'] = True #where True = Highway\n",
    "\n",
    "# Add weather_cat column to consolidate weather conditions\n",
    "conditions = [df['Weather_Condition'].str.contains('Clear|Fair', case=False) == True,\n",
    "              df['Weather_Condition'].str.contains('Cloud|Overcast', case=False) == True,\n",
    "              df['Weather_Condition'].str.contains('Rain|Storm', case=False) == True,\n",
    "              df['Weather_Condition'].str.contains('Heavy Rain|Rain Shower|Heavy T-Storm|Heavy Thunderstorms', case=False) == True,\n",
    "              df['Weather_Condition'].str.contains('Snow|Sleet|Ice', case=False) == True,\n",
    "              df['Weather_Condition'].str.contains('Heavy Snow|Heavy Sleet|Heavy Ice Pellets|Snow Showers|Squalls', case=False) == True,\n",
    "              df['Weather_Condition'].str.contains('Fog', case=False) == True]\n",
    "choices = ['Clear', 'Cloud', 'Rain', 'Heavy_rain', 'Snow', 'Heavy_Snow','Fog']\n",
    "df['Weather_Condition'] = np.select(conditions, choices, default='Other') # Assign null value as clear\n",
    "\n",
    "# Clean wind direction\n",
    "df['Wind_Direction'].replace({'North':'N','West':'W','East':'E','Variable':'VAR','South':'S'}, inplace=True)\n",
    "\n",
    "# Add weekday\n",
    "df['Weekday'] = df['Start_Time'].dt.dayofweek\n",
    "\n",
    "# Add month\n",
    "df['Month'] = df['Start_Time'].dt.month\n",
    "\n",
    "# Add year\n",
    "df['Year'] = df['Start_Time'].dt.year\n",
    "\n",
    "# Add season category\n",
    "conditions = (df.Month < 3, df.Month < 5, df.Month < 8, df.Month <12, df.Month == 12)\n",
    "choices = ['winter', 'spring','summer', 'fall', 'winter']\n",
    "df['Season'] = np.select(conditions, choices, default=np.nan)\n",
    "\n",
    "# Add incident duration\n",
    "df['Duration'] = (df['End_Time'] - df['Start_Time']).dt.total_seconds().div(60).astype(int)\n",
    "\n",
    "## Add Traffic_Calming_ex_Bump\n",
    "df['Traffic_Calming_ex_Bump'] = df['Traffic_Calming']\n",
    "df['Traffic_Calming_ex_Bump'] = np.where(df.Bump == True, False, df['Traffic_Calming_ex_Bump'])\n",
    "\n",
    "## Add Any_poi (collapsed poi)\n",
    "df['Any_poi'] = df[poi].any(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Descriptive Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incident Description and Severity\n",
    "# Visualise common terms in description of incident\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "descriptors = list(df['Description'])\n",
    "text = \" \".join(descriptors)\n",
    "\n",
    "wordcloud = WordCloud(width = 3000, height = 2000, random_state=1,\n",
    "    background_color='white', colormap='Set1', collocations=False, stopwords = STOPWORDS, color_func=lambda *args, **kwargs: \"#00a79d\").generate(text)\n",
    "plt.figure(figsize=(16, 20))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "id": "hNymiOiy5p0S",
    "outputId": "915a0aa7-f9a2-457d-c883-19a5599293b4"
   },
   "outputs": [],
   "source": [
    "# Severity\n",
    "# Plot percentage of severity by category\n",
    "severity_prop = pd.DataFrame()\n",
    "severity_prop['count'] = df['Severity'].groupby(df['Severity']).count()\n",
    "severity_prop['percent'] = (severity_prop['count'] / severity_prop['count'].sum())*100\n",
    "\n",
    "ax = severity_prop['percent'].plot(kind='bar', xlabel='Severity', ylabel='Traffic Incidents (%)', colormap=ListedColormap(sns.color_palette('mako')))\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt= \"%.2f\")\n",
    "ax.set_xticklabels(['Low','Medium','High','Very High'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance and Duration\n",
    "# Explore Distance variable\n",
    "fig, ax = plt.subplots(2, 2)\n",
    "fig.set_figheight(4)\n",
    "fig.set_figwidth(9)\n",
    "sns.stripplot(ax = ax[0,0], x='Distance', data=df)\n",
    "sns.boxplot(ax = ax[0,1], x='Distance', data=df, palette='mako', showfliers=False)\n",
    "sns.stripplot(ax = ax[1,0], x='Duration', data=df)\n",
    "sns.boxplot(ax = ax[1,1], x='Duration', data=df, palette='mako', showfliers=False)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df to organise distance to bins\n",
    "distance_prop = pd.cut(df['Distance'],\n",
    "             bins=[0, 1, 2, 3, 4, 5, np.inf],\n",
    "             labels=['<1','1 - 1.999','2 - 2.999', '3 - 3.999', '4 - 4.999', '>=5']).reset_index().groupby('Distance').count()\n",
    "distance_prop = pd.DataFrame(distance_prop.reset_index().values)\n",
    "distance_prop.set_axis(['distance_bin','count'], axis=1, inplace=True)\n",
    "distance_prop['percent'] = distance_prop['count'].apply(lambda x: x / distance_prop['count'].sum() * 100)\n",
    "\n",
    "# Visualise distance_bins\n",
    "ax = sns.barplot(x='distance_bin', y='percent', data=distance_prop, palette = 'mako')\n",
    "ax.set(title='', xlabel=\"Distance Bin\", ylabel=\"Traffic Incidents (%)\")\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt= \"%.2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarise distance and duration\n",
    "num_dd = ['Distance','Duration'] # weather columns containing numerical variables\n",
    "df_dd = df[num_dd].describe().T\n",
    "df_dd = pd.concat([df_dd, df[num_dd].skew()], axis=1).rename(columns={0:'Skewness'})\n",
    "df_dd = pd.concat([df_dd, df[num_dd].kurt()], axis=1).rename(columns={0:'Kurtosis'})\n",
    "display(df_dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "D3MQifkuO5YJ",
    "outputId": "48b5591f-f42e-4ac0-d6da-c6fa46f80b19"
   },
   "outputs": [],
   "source": [
    "# Weather variables\n",
    "# Summarise weather data\n",
    "num_weather = ['Temperature', 'Wind_Chill', 'Humidity', 'Pressure', 'Wind_Speed','Precipitation'] # weather columns containing numerical variables\n",
    "df_weather_stats = df[num_weather].describe().T\n",
    "df_weather_stats = pd.concat([df_weather_stats, df[num_weather].skew()], axis=1).rename(columns={0:'Skewness'})\n",
    "df_weather_stats = pd.concat([df_weather_stats, df[num_weather].kurt()], axis=1).rename(columns={0:'Kurtosis'})\n",
    "display(df_weather_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hUJEK862oOk5",
    "outputId": "71fe3065-e2c1-4b39-c455-4c98103b0bbc"
   },
   "outputs": [],
   "source": [
    "# Plot distribution of weather data\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "fig.set_figheight(3)\n",
    "fig.set_figwidth(14)\n",
    "sns.histplot(ax = ax[0], x='Temperature', data=df, stat='percent', kde=True, bins=16)\n",
    "sns.histplot(ax = ax[1], x='Wind_Speed', data=df, stat='percent', kde=True, bins=16)\n",
    "sns.histplot(ax = ax[2], x='Precipitation', data=df, stat='percent', kde=True, bins=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "gkzjpQ81GxWx",
    "outputId": "30baa4f3-9b64-404e-e86b-1680a6198ce5"
   },
   "outputs": [],
   "source": [
    "# Boxplot each weather variable\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "fig.set_figheight(4)\n",
    "fig.set_figwidth(9)\n",
    "sns.boxplot(ax = ax[0], x='Severity',y='Temperature', data=df, palette='mako', showfliers=False)\n",
    "sns.boxplot(ax = ax[1], x='Severity',y='Wind_Speed', data=df, palette='mako', showfliers=False)\n",
    "plt.setp(ax, xticks=[0, 1, 2, 3], xticklabels=['Low', 'Medium', 'High', 'Very High'])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for Temperature, Pressure & Humidity for each Severity category\n",
    "columns = ['Temperature', 'Wind_Speed', 'Precipitation']\n",
    "df_weather_stats2 = df.groupby('Severity')[columns].describe().T\n",
    "display(df_weather_stats2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accident Frequency by Temperature\n",
    "temp_prop = pd.cut(df['Temperature'],\n",
    "             bins=[np.NINF,0, 10, 20, 30, np.inf],\n",
    "             labels=['<0','0 - 9','10 - 19', '20 - 29', '30+']).reset_index().groupby('Temperature').count()\n",
    "temp_prop  = pd.DataFrame(temp_prop.reset_index().values)\n",
    "temp_prop .set_axis(['temperature_bin','count'], axis=1, inplace=True)\n",
    "temp_prop ['percent'] = temp_prop['count'].apply(lambda x: x / temp_prop['count'].sum() * 100)\n",
    "\n",
    "# Visualise distance_bins\n",
    "ax = sns.barplot(x='temperature_bin', y='percent', data=temp_prop, palette = 'mako')\n",
    "ax.set(title='', xlabel=\"Temperature\", ylabel=\"Traffic Incidents (%)\")\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt= \"%.2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accident Frequency by Wind_speed\n",
    "wsp_prop = pd.cut(df['Wind_Speed'],\n",
    "             bins=[np.NINF,0, 10, 20, 30, np.inf],\n",
    "             labels=['<0','0 - 9','10 - 19', '20 - 29', '30+']).reset_index().groupby('Wind_Speed').count()\n",
    "wsp_prop  = pd.DataFrame(wsp_prop.reset_index().values)\n",
    "wsp_prop .set_axis(['wsp_bin','count'], axis=1, inplace=True)\n",
    "wsp_prop ['percent'] = wsp_prop['count'].apply(lambda x: x / wsp_prop['count'].sum() * 100)\n",
    "\n",
    "# Visualise distance_bins\n",
    "ax = sns.barplot(x='wsp_bin', y='percent', data=wsp_prop, palette = 'mako')\n",
    "ax.set(title='', xlabel=\"Wind Speed\", ylabel=\"Traffic Incidents (%)\")\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt= \"%.2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accident Frequency by Precipitation\n",
    "precip_prop = pd.cut(df['Precipitation'],\n",
    "             bins=[np.NINF,0.0001, 3, 6, 9, np.inf],\n",
    "             labels=['0','1-3','4 - 6','7 - 9', '10+']).reset_index().groupby('Precipitation').count()\n",
    "precip_prop  = pd.DataFrame(precip_prop.reset_index().values)\n",
    "precip_prop .set_axis(['precip_bin','count'], axis=1, inplace=True)\n",
    "precip_prop ['percent'] = precip_prop['count'].apply(lambda x: x / precip_prop['count'].sum() * 100)\n",
    "\n",
    "# Visualise distance_bins\n",
    "ax = sns.barplot(x='precip_bin', y='percent', data=precip_prop, palette = 'mako')\n",
    "ax.set(title='', xlabel=\"Precipitation\", ylabel=\"Traffic Incidents (%)\")\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt= \"%.2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Road type\n",
    "# Visualise common terms in description of incident\n",
    "descriptors = list(df['Street'])\n",
    "text = \" \".join(descriptors)\n",
    "\n",
    "wordcloud = WordCloud(width = 3000, height = 2000, random_state=1,\n",
    "    background_color='white', colormap='Set1', collocations=False, stopwords = STOPWORDS, color_func=lambda *args, **kwargs: \"#00a79d\").generate(text)\n",
    "plt.figure(figsize=(16, 20))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Street Type column to remove abbreviations of streets\n",
    "conditions = [df['Street'].str.contains('Ave|Avenue', case = False) == True, \n",
    "              df['Street'].str.contains('St|Street', case = False) == True,\n",
    "              df['Street'].str.contains('Rd|Road', case = False) == True,\n",
    "              df['Street'].str.contains('Blvd|Boulevard', case = False) == True,\n",
    "              df['Street'].str.contains('Pkwy|Parkway', case = False) == True,\n",
    "              df['Street'].str.contains('Dr|Drive', case = False) == True,\n",
    "              df['Street'].str.contains('I-|Interstate', case = False) == True,\n",
    "              df['Street'].str.contains('Expy|Exp|Expressway', case = False) == True,\n",
    "              df['Street'].str.contains('Route', case = False) == True,\n",
    "              df['Street'].str.contains('State', case = False) == True,\n",
    "              df['Street'].str.contains('NY', case = False) == True,\n",
    "              df['Street'].str.contains('Trwy|Throughway', case = False) == True,\n",
    "              df['Street'].str.contains('US', case = False) == True,\n",
    "              df['Street'].str.contains('Hwy|Highway|Wyck|9n', case = False) == True, \n",
    "              df['Street'].str.contains('Loop', case = False) == True,\n",
    "              df['Street'].str.contains('Bridge|Brg', case = False) == True, \n",
    "              df['Street'].str.contains('Cross', case = False) == True,\n",
    "              df['Street'].str.contains('Ext|Exit', case = False) == True,\n",
    "              df['Street'].str.contains('Broadway', case = False) == True,\n",
    "              df['Street'].str.contains('Place|Pl', case = False) == True,\n",
    "              df['Street'].str.contains('Bay|Shore', case = False) == True,\n",
    "              df['Street'].str.contains('city|main|way|line', case = False) == True,]\n",
    "choices = ['Ave', 'St', 'Rd', 'Blvd', 'Parkway', 'Dr', 'Interstate Highway', 'ExpressWay', 'Route', 'State', 'NY Highway', 'ThroughWay', 'US highway', 'Highway', 'Loop', 'Bridge', 'Cross', 'Exit', 'Broadway' ,'Place', 'Bay/shore', 'Random']\n",
    "df['street_type'] = np.select(conditions, choices, default=np.nan)\n",
    "df.groupby(['street_type'])['street_type'].count() # Count of stret types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accident by Road Type\n",
    "ax = sns.barplot(x='Highway', y='Severity', data=df, estimator=lambda x: len(x) / len(df) * 100 , palette = 'mako')\n",
    "ax.set(title='', xlabel=\"Highway\", ylabel=\"Traffic Indcidents (%)\")\n",
    "ax.set_xticklabels(['Non-Highway','Highway'])\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt= \"%.2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "_0hcUJhacvQI",
    "outputId": "7b453906-ff50-48b8-9903-3fba8a8a1051"
   },
   "outputs": [],
   "source": [
    "# Accidents and Time\n",
    "# Accident Severity Counts by Year\n",
    "ax = sns.barplot(x='Year', y='Year', data=df, estimator=lambda x: len(x) / len(df) * 100 , palette = 'mako')\n",
    "ax.set(title='', xlabel=\"Year\", ylabel=\"Traffic Incidents (%)\")\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt= \"%.2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "UYyEgt5OcybJ",
    "outputId": "4a8acc45-9614-4410-cc12-9f27a714e366"
   },
   "outputs": [],
   "source": [
    "# Accident Severity Counts by Day of Week\n",
    "ax = sns.barplot(x='Weekday', y='Weekday', data=df, estimator=lambda x: len(x) / len(df) * 100, palette = 'mako')\n",
    "ax.set(title='', xlabel = \"Weekday\", ylabel=\"Traffic Incidents (%)\")\n",
    "ax.set_xticklabels(['Mon', 'Tues', 'Wed', 'Thurs','Fri','Sat','Sun'])\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt= \"%.2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "GZL4pQmyhzWs",
    "outputId": "cc8f18a3-0840-4633-85bc-74fded52b2b2"
   },
   "outputs": [],
   "source": [
    "# Number of accidents per hour\n",
    "ax = sns.barplot(x=df['Start_Time'].dt.hour, y='Severity', data=df, estimator=lambda x: len(x) / len(df) * 100 , palette = 'mako')\n",
    "ax.set(title='', xlabel=\"Hour\", ylabel=\"Traffic Incidents (%)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "pZ6bbpijc5po",
    "outputId": "ed827165-8423-4d3d-a0ec-da592c1de247"
   },
   "outputs": [],
   "source": [
    "# Accident Severity Counts by Day/Night\n",
    "ax = sns.barplot(x='Sunrise_Sunset', y='Severity', data=df, estimator=lambda x: len(x) / len(df) * 100 , palette = 'mako')\n",
    "ax.set(title='', xlabel=\"Time of Day\", ylabel=\"Traffic Incidents (%)\")\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt= \"%.2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "RLqQ-HfJczoR",
    "outputId": "e5666b8a-bbee-4f79-a42f-2c1c8037e98f"
   },
   "outputs": [],
   "source": [
    "# Accident Severity Counts by Season\n",
    "ax = sns.barplot(x='Season', y='Severity', order = ['spring','summer','fall','winter'], estimator=lambda x: len(x) / len(df) * 100, data=df,  palette = 'mako')\n",
    "ax.set(title='', xlabel = \"Season\", ylabel=\"Traffic Incidents (%)\")\n",
    "ax.set_xticklabels(['Spring','Summer', 'Winter', 'Fall'])\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt= \"%.2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "ozlhCeKRcw6L",
    "outputId": "16aea751-9094-4fcc-f7b3-d7fc964780f6"
   },
   "outputs": [],
   "source": [
    "# Accident Severity Counts by Month\n",
    "ax = sns.barplot(x='Month', y='Month', data=df, estimator=lambda x: len(x) / len(df) * 100 , palette = 'mako')\n",
    "ax.set(title='', xlabel=\"Month\", ylabel=\"Traffic Incidents (%)\")\n",
    "ax.set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'])\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt= \"%.2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "Wn5RPUomh08T",
    "outputId": "217ee87c-86b4-4639-d487-179bfe261b66"
   },
   "outputs": [],
   "source": [
    "# Accident Severity Counts by Weather Conditions\n",
    "plot_order = df.groupby('Weather_Condition')['Weather_Condition'].count().sort_values(ascending=False).index.values\n",
    "ax = sns.barplot(x='Weather_Condition', y='Severity', data=df, estimator=lambda x: len(x) / len(df) * 100 ,order=plot_order, palette = 'mako')\n",
    "ax.set(title='', xlabel=\"Weather Condition\", ylabel=\"Traffic Incidents (%)\")\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt= \"%.2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "teiI1q5EA5Y0",
    "outputId": "1471f269-dc9f-459d-eeed-00c6aea7d1bb"
   },
   "outputs": [],
   "source": [
    "# Explore Points of Interest\n",
    "# Summarise poi data\n",
    "selection = poi + ['Severity']\n",
    "poi_summary = df[selection].groupby('Severity', observed=True).agg('sum')\n",
    "poi_summary['Total'] = poi_summary.sum(axis=1)\n",
    "poi_summary = poi_summary.transpose(copy=True)\n",
    "poi_summary['Total'] = poi_summary.sum(axis=1)\n",
    "display(poi_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "id": "kzY93HYHR1-i",
    "outputId": "6065c685-76fc-48ea-a22b-c9610ffac542"
   },
   "outputs": [],
   "source": [
    "## Pie plot of Any_poi variable\n",
    "labels = ['No', 'Yes'] \n",
    "plt.pie(df['Any_poi'].value_counts(), labels = labels, autopct = '%1.2f%%', labeldistance=1.1, explode=[0, 0.15], colors=(sns.color_palette('mako')[4], sns.color_palette('mako')[5]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot frequency of POI\n",
    "poi_counts = df[poi].melt()\n",
    "poi_counts = pd.crosstab(index=poi_counts['variable'], columns=poi_counts['value'])\n",
    "poi_counts = poi_counts[1].sort_values(ascending=True)\n",
    "\n",
    "ax = poi_counts.plot.barh(cmap=ListedColormap(sns.color_palette('mako')))\n",
    "ax.set(title='', xlabel=\"No. Observations\", ylabel=\"Point of Interest\")\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt= \"%.0f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency of Severity by POI\n",
    "df_poi = pd.DataFrame()\n",
    "for p in poi:\n",
    "    melted_df = df.melt(id_vars=['Severity'], value_vars = [p])\n",
    "    melted_df = pd.crosstab(index=melted_df['Severity'], columns=melted_df['value'])\n",
    "    df_poi[p] = round((melted_df[1] / melted_df[1].sum())*100,2)\n",
    "\n",
    "df_poi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "id": "zfd_o7i8cqbj",
    "outputId": "0564eef4-2864-42e3-87ae-0f73eeef1b91"
   },
   "outputs": [],
   "source": [
    "# Correlations\n",
    "# Find correlations for weather features\n",
    "cols = ['Severity'] + weather\n",
    "corr = df[cols].corr()\n",
    "x = corr[0:1].drop(columns=['Severity'])\n",
    "\n",
    "# Plot correlation to Severity\n",
    "plt.figure(figsize=(8,2))\n",
    "sns.heatmap(x, cmap='mako', annot=True, cbar_kws=dict(use_gridspec=False,location=\"top\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 662
    },
    "id": "8SFTNVnLcqO8",
    "outputId": "634c1af9-90e0-4e0f-c74c-c5d292013252"
   },
   "outputs": [],
   "source": [
    "## Find correlations for poi features \n",
    "cols = ['Severity'] + poi\n",
    "corr = df[cols].corr()\n",
    "x = corr[0:1].drop(columns=['Severity'])\n",
    "\n",
    "# Plot correlation to Severity\n",
    "plt.figure(figsize=(10,2))\n",
    "sns.heatmap(x, cmap='mako', annot=True, cbar_kws=dict(use_gridspec=False,location=\"top\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency of accidents on highways, compared to other road types.\n",
    "# Boxplot each variable\n",
    "fig, ax = plt.subplots(3, 3)\n",
    "fig.set_figheight(7)\n",
    "fig.set_figwidth(9)\n",
    "sns.boxplot(ax = ax[0, 0], x='Highway',y='Temperature', data=df, showfliers=False, palette='mako')\n",
    "sns.boxplot(ax=ax[0, 1], x='Highway',y='Wind_Chill', data=df, showfliers=False, palette='mako')\n",
    "sns.boxplot(ax= ax[0, 2], x='Highway',y='Humidity', data=df, showfliers=False, palette='mako')\n",
    "sns.boxplot(ax = ax[1, 0], x='Highway',y='Pressure', data=df, showfliers=False, palette='mako')\n",
    "sns.boxplot(ax = ax[1, 1], x='Highway',y='Visibility', data=df, showfliers=False, palette='mako')\n",
    "sns.boxplot(ax = ax[1, 2], x='Highway',y='Wind_Speed', data=df, showfliers=False, palette='mako')\n",
    "sns.boxplot(ax = ax[2, 0], x='Highway',y='Precipitation', data=df, showfliers=False, palette='mako')\n",
    "sns.boxplot(ax = ax[2, 1], x='Highway',y='Distance', data=df, showfliers=False, palette='mako')\n",
    "fig.delaxes(ax[2][2])\n",
    "plt.setp(ax, xticks=[0, 1], xticklabels=['Highway', 'Non-Highway'])\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "pTmEQPkEc9XZ",
    "outputId": "ed650ca2-ef69-4050-ce9e-3daf87c3ae29"
   },
   "outputs": [],
   "source": [
    "# Accident Severity Frequency by Road Type\n",
    "ax = sns.barplot(x='Severity', y='Highway', hue='Highway', data=df, estimator=lambda x: len(x) / len(df) * 100 , palette = 'mako')\n",
    "ax.set(title='', xlabel=\"Highway\", ylabel=\"Traffic Indcidents (%)\")\n",
    "ax.set_xticklabels(['Low','Medium','High','Very High'])\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt= \"%.2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bartlett's & Welch's ANOVA means of Weather vs. Road type\n",
    "cols = ['Distance','Temperature', 'Wind_Chill', 'Humidity', 'Pressure','Visibility','Wind_Speed','Precipitation']  \n",
    "\n",
    "df_tests = pd.DataFrame(columns=['Variable','chi_sq', 'p-value', 'F','p-value'])\n",
    "for column in df[cols]:\n",
    "    b_stat, b_p = stats.bartlett(df[df['Severity']==1][column], df[df['Severity']==2][column], df[df['Severity']==3][column], df[df['Severity']==4][column])\n",
    "    aov = welch_anova(dv=column, between = 'Highway', data=df)\n",
    "    aov_f = np.array(aov['F'])[0]\n",
    "    aov_p = np.array(aov['p-unc'])[0]\n",
    "    df_tests.loc[len(df_tests)] = [column, b_stat, b_p, aov_f, aov_p]\n",
    "    \n",
    "df_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bartlett's & Welch's ANOVA means of Weather/Distance vs. Severity\n",
    "cols = ['Distance','Temperature', 'Wind_Chill', 'Humidity', 'Pressure','Visibility','Wind_Speed','Precipitation']  \n",
    "\n",
    "df_tests = pd.DataFrame(columns=['Variable','chi_sq', 'p-value', 'F','p-value'])\n",
    "for column in df[cols]:\n",
    "    b_stat, b_p = stats.bartlett(df[df['Severity']==1][column], df[df['Severity']==2][column], df[df['Severity']==3][column], df[df['Severity']==4][column])\n",
    "    aov = welch_anova(dv=column, between = 'Severity', data=df)\n",
    "    aov_f = np.array(aov['F'])[0]\n",
    "    aov_p = np.array(aov['p-unc'])[0]\n",
    "    df_tests.loc[len(df_tests)] = [column, b_stat, b_p, aov_f, aov_p]\n",
    "\n",
    "df_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tukey HSD\n",
    "for column in df[cols]:\n",
    "    print(\"\\nTukey HSD results for \"+column)\n",
    "    comp = MultiComparison(df[column], df['Severity']).tukeyhsd().summary()\n",
    "    print(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarise Weather by Road Type\n",
    "df_stats = df.groupby(['Highway']).agg({'Precipitation':{'mean','std'},'Pressure':{'mean','std'},'Visibility':{'mean','std'}, 'Wind_Chill':{'mean','std'}, 'Humidity':{'mean','std'}, 'Temperature':{'mean','std'}, 'Wind_Speed':{'mean','std'}})\n",
    "df_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats2 = df.groupby(['Highway']).agg({'Distance':{'count','mean','std'}})\n",
    "df_stats2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Presence of a point-of-interest its impact on traffic event  \n",
    "# Accident Severity Frequency and Points of Interest\n",
    "x, y = 'Any_poi', 'Severity'\n",
    "df_plot = df.groupby(x)[y].value_counts(normalize=True)\n",
    "df_plot = df_plot.mul(100)\n",
    "df_plot = df_plot.rename('percent').reset_index()\n",
    "\n",
    "ax = sns.catplot(x=x,y='percent',hue=y,kind='bar',data=df_plot, legend_out = False, palette='mako')\n",
    "ax.set(title='', xlabel=\"Point of Interest Observed\", ylabel=\"Traffic Indcidents (%)\")\n",
    "ax.set_xticklabels(['No','Yes'])\n",
    "ax.ax.set_ylim(0,100)\n",
    "\n",
    "for p in ax.ax.patches:\n",
    "    txt = str(p.get_height().round(2)) + '%'\n",
    "    txt_x = p.get_x() \n",
    "    txt_y = p.get_height()\n",
    "    ax.ax.text(txt_x,txt_y,txt)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barplots of POI by Severity\n",
    "col = df_poi.columns\n",
    "counter = 1\n",
    "fig = plt.figure(figsize=(10,15))\n",
    "for i in col:\n",
    "    plt.subplot(4,3,counter)\n",
    "    ax = df_poi[i].plot(kind='bar', title=i, xlabel='Severity', ylabel='Ratio (%)', rot=0, colormap=ListedColormap(sns.color_palette('mako')))\n",
    "    ax.set_xticklabels(['Low', 'Medium', 'High', 'Very High'])\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container, fmt= \"%.2f\")\n",
    "    counter += 1\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XJ3wSmM3h6Ij"
   },
   "outputs": [],
   "source": [
    "# Classification modelling to identify which factors most influence accident Severity\n",
    "# Prepare training and test data\n",
    "include = ['Start_Lat', 'Start_Lng', 'Distance', 'Temperature', 'Wind_Chill', 'Humidity', 'Pressure', 'Visibility', 'Wind_Speed', 'Precipitation', 'Amenity', 'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station', 'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Highway', 'Weekday', 'Month', 'Year']\n",
    "df_feat = df[include].copy()\n",
    "df_target = df.Severity.copy()\n",
    "\n",
    "# Normalise the data\n",
    "cols_to_norm = ['Start_Lat', 'Start_Lng', 'Distance','Temperature', 'Wind_Chill', 'Humidity', 'Pressure', 'Visibility',\n",
    "       'Wind_Speed', 'Precipitation', 'Weekday', 'Month','Year']\n",
    "df_feat[cols_to_norm] = df_feat[cols_to_norm].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "\n",
    "# Split training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_feat, df_target, test_size = 0.3, random_state=1)\n",
    "\n",
    "# Output size of test and training sets\n",
    "print(\"Training set size is: \", len(X_train))\n",
    "print(\"Test set size is: \", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K5pr5kdcoZpH"
   },
   "outputs": [],
   "source": [
    "# Balance training dataset\n",
    "smo_tek = SMOTETomek(random_state=1)\n",
    "X_train, y_train = smo_tek.fit_resample(X_train, y_train)\n",
    "\n",
    "# Create df to store model performance \n",
    "results = pd.DataFrame(columns = ['Model','Precision', 'Recall','F1-Score','Accuracy'])\n",
    "\n",
    "# Output info after balancing\n",
    "print(\"Balanced training set size is: \", len(X_train))\n",
    "\n",
    "df_train = y_train.value_counts().rename_axis('Severity').reset_index(name='Count')\n",
    "display(df_train.sort_values('Severity').style.hide(axis='index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lJHuUZ0giK_L"
   },
   "outputs": [],
   "source": [
    "# Supervised Learning with K-Nearest Neghbours\n",
    "parameters = {'n_neighbors': np.arange(1, 50)}\n",
    "\n",
    "# Find the best value of n parameters using random search\n",
    "knn = RandomizedSearchCV(KNeighborsClassifier(), parameters, random_state=1, cv = 5, scoring='f1_weighted')\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Return parameters of model with highest accuracy\n",
    "optimal_model = knn.best_estimator_\n",
    "print('Best parameters are: ')\n",
    "print( knn.best_params_)\n",
    "\n",
    "n_results = pd.DataFrame(knn.cv_results_)[['params', 'mean_test_score']] # save results of random search\n",
    "\n",
    "knn_predictions = knn.predict(X_test) # Perform prediction on test data\n",
    "results.loc[len(results)] = scores('K-Nearest Neighbours (k='+np.array2string(knn.best_params_['n_neighbors'])+')', y_test, knn_predictions) # Store metrics to results df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot random search performance for different values of k\n",
    "n_results = pd.DataFrame(knn.cv_results_)[['params', 'mean_test_score']]\n",
    "n_results['params'] = n_results['params'].apply(pd.Series)\n",
    "ax = sns.lineplot(x='params', y='mean_test_score', data=n_results)\n",
    "ax.set(title='', xlabel=\"N\", ylabel=\"Mean Test Score (%)\")\n",
    "plt.show()\n",
    "\n",
    "n_results.sort_values('mean_test_score', ascending=False).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test KNN for optimal k + 3\n",
    "kparam=knn.best_params_['n_neighbors']+3\n",
    "KNNClassifier = KNeighborsClassifier(n_neighbors=kparam)\n",
    "KNNClassifier.fit(X_train, y_train)\n",
    "knn_predictions = KNNClassifier.predict(X_test)\n",
    "value = str(kparam)\n",
    "results.loc[len(results)] = scores('K-Nearest Neighbours (k='+value+')', y_test, knn_predictions) # Store metrics to results df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mVB2RR20iSud"
   },
   "outputs": [],
   "source": [
    "# Unsupervised Learning with Random Forest\n",
    "parameters = {'n_estimators': [500, 1000, 1500, 2000],\n",
    "               'max_depth': [20, 40, 60, 80, 100],\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'min_samples_leaf': [1, 2, 4]}\n",
    "\n",
    "rf = RandomizedSearchCV(RandomForestClassifier(), parameters, cv = 2, random_state=1, scoring='f1_weighted', verbose = 0)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Return parameters of model with highest accuracy\n",
    "optimal_model = rf.best_estimator_\n",
    "print('Best parameters are: ')\n",
    "print( rf.best_params_)\n",
    "\n",
    "rf_predictions = rf.predict(X_test) # Perform prediction on test data\n",
    "\n",
    "results.loc[len(results)] = scores('Random Forest', y_test, rf_predictions) # Store metrics to results df\n",
    "\n",
    "# Plot important features\n",
    "feature_names = df_feat.columns\n",
    "importances = rf.best_estimator_.feature_importances_\n",
    "\n",
    "forest_importances = pd.Series(importances, index=feature_names).sort_values(ascending=True)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.barh(ax=ax)\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YKjnoFBuiZJv"
   },
   "outputs": [],
   "source": [
    "# Output results of models\n",
    "display(results.round(4).style.hide(axis = 'index'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
